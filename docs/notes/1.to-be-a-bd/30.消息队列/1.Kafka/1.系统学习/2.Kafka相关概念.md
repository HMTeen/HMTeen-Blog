---
title: Kafka相关概念
createTime: 2025/03/31 16:20:35
permalink: /ToBeABD/MQ/Kafka/936x4j0s/
---
# Kafka基本

==【八股】Kafka有哪些特点？==

- **高吞吐量、低延迟**：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒；

- **可扩展性**：kafka集群支持热扩展；

- **持久性、可靠性**：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失；

- **容错性**：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）；

- **高并发**：支持数千个客户端同时读写；

---

==【八股】使用Kafka的场景？==

- **收集日志**：用Kafka收集各个服务的日志，通过Kafka以统一接口服务的方式开放给各种consumer，例如Hadoop、HBase等；

- **消息队列**：用作消息队列，解耦各个服务间的关系；
- **用户活动跟踪**：记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘；



# Kafka架构设计

![image-20250331175137795](./assets/image-20250331175137795.png)

|                |                                                              |
| -------------- | ------------------------------------------------------------ |
| Producer       | 消息生产者，向Kafka发送消息的客户端                          |
| Consumer       | 消息消费者，向Kafka Broker取消息的客户端                     |
| Topic          | 可以理解为一个队列，一个Topic可以分为一个或多个分区（Partition） |
| Consumer Group | 是Kafka实现广播（发给所有Consumer）和单播（发给任一Consumer）的手段，一个Topic可以有多个Consumer Group |
| Broker         | 一台Kafka服务器就是一个Broker（1个Broker可以容纳多个Topic），一个集群由多个Broker组成。 |
| Partition      | （1）为了实现扩展性，一个非常大的Topic可能有多个Partition，分布到多个Broker上，每个Partition是一个有序的队列。Partition中的消息都会被分配一个有序的id（Offset）；<br />（2）Kafka只保证一个Partition中消息消费的有序性，无法保证一个Topic整体消息消费的顺序（涉及多个Partition） |
| Offset         | Kafka的存储文件都是按照`offset.kafka`来命名，方便查找（比如2049的消息，找最近的且编号小于2049的文件，例如2048.kafka） |



# 相关八股 | 架构

## Producer

==【八股】集群下，Kafka中Producer的执行过程？==

1、Producer生产消息，确定要写入的Topic和对应的Partition；

2、从zookeeper中找到对应Partition的Leader；

3、通过ISR列表将消息通知给对应的Follower；

4、Follower从Leader拉取消息，并发送Ack；

5、Leader收到所有副本的Ack，更新Offset，并向Producer发送Ack，表示消息写入成功；

---

==【八股】生产者发送消息的流程？==

![image-20250401152030233](./assets/image-20250401152030233.png)

- 拦截器：可以自定义，默认没有拦截器；
- 序列化器：可以在配置文件中为消息的键、值各自选择合适的序列化器；
- 分区器：可以根据业务场景，自定义分区器，用于将消息写入对应的Partition；

---

==【八股】Kafka的消息是Push模式还是Pull模式？==

Kafka的消息模式是：

- Producer -> Broker：**Push模式**，即生产者主动将消息发送给Kafka；
- Broker -> Consumer：**Pull模式**，即消费者从Kafka中拉取消息；

---

Pull模式的优点：

- 【消费者可以控制消费节奏】：不同消费者的消费能力不同，Pull的方式可以让消费者按照自己的节奏消费消息，消费能力比较灵活；
- 【方便实现批量消费】：Pull模式下，消费者可以决定是单独消费消息还是批量消费消息，比较灵活；

- 【消费策略更灵活】：比如手动提交offset、延迟消费、重试机制等都更容易实现；

Pull模式的缺点：

- 【轮询消耗资源】：如果Broker没有可供消费的消息，将导致Consumer不断在循环中轮询；
- 【Kafka解决措施】：Kafka可以设置参数，让Consumer能阻塞式的知道是否有新消息到达（或到达消息的数量是否到某个数值）；

---

Push模式的优点：

- 【低延迟】：消息一旦产生就立即推送，延迟小，适合对实时性要求比较高的场合，比如：实时报警
- 【对消费者来说，实现简单】：消费者无需关注消息拉取的细节、Offset等逻辑，只需要接收消息并处理即可；

Push模式的缺点：

- 【缺乏消费节奏的控制】
- 【不易实现批量处理】

- 【难实现重试和容错】

- 【对Broker的调度能力要求高】

---





## Consumer

==【八股】消费者消费消息的流程？==





==【八股】讲一下Kafka Consumer消费消息时的线程模型，为何如此设计？==

待定。



## Partition

==【八股】Kafka分区（Partition）的目的是什么？==

**对于生产者 | 提高Kafka集群的数据生产能力并实现负载均衡**

- 一个Topic的不同Partition，可以分布在不同的Broker上，生产者可以并行写入，提高写入速度；
- 当多个生产者同时写入同一个主题时，由于分区机制，写入操作可以分布在不同Broker上，减少单点压力，实现负载均衡；

**对于消费者 | 提高Kafka集群的数据消费能力**：

- 每个Topic可以有多个Partition，Kafka的Consumer Group可以并行消费不同Partition的数据；
- 通过设置分区，可以让更多的消费者同时消费，提升吞吐量；

**对于消费者 | 保证数据有序性**

- Kafka只能在Partition内保证消息消费的有序性；
- 如果某类业务场景的消息需要按照顺序消费，可以使用分区键（Partition Key），使得相同键的消息进入同一分区，再被同一个消费者来消费；

---

==【八股】Kafka如何做到消息的有序性？==

- Kafka中每个Partition是一个有序的、不可变的日志队列；并且单独的一个Partition只能由一个Consumer来消费；
- 将同一类型的消息，通过分区键来写入到同一个Partition，就能保证该类型消息消费的有序性；

---

==【八股】为什么Kafka的Partition只能增加不能减少？==

Kafka的Partition数量可以变更，但是只能增加不能减少，原因如下：

- 数据存放问题：如果减少分区，对应的数据如何处理？删除数据，就会导致数据丢失；保留数据到其他Partition，就会破坏Partition的分区有序性；

- 增加实现复杂度：如果保留数据并且保证Partition的分区有序性，实现难度会很大，所以就禁止减少分区数量；

---

==【八股】生产者将消息写入Partition的策略是啥？==

> 即：怎么确定一条消息写入到Topic中哪个Partition里面

**消息写入策略有如下**：

轮询策略（Round-Robin）：

- 当没有指定Key的时候，生产者按照轮询方式将消息依次分配到所有可用的Partition；
- 能保证负载均衡，但无法保证消息有序；

Key分区策略：

- 当消息包含Key，Kafka对Key进行哈希处理，来确定消息分配到哪个Partition；
- 可以保证消息的顺序性；

自定义分区策略：

- 通过自定义`Partitioner`，来实现特定的消息写入策略；
- 灵活性高，但是需要开发者自行实现和维护；

**消息写入策略的最佳实践**：

- 【选择合适的分区数量】：保证平衡负载；过多分区数量会增加管理开销，过少分区数量会影响并行处理能力；
- 【优化Key的选取】：使得消息能够均匀分布到各个Partition，避免数据倾斜。对于需要保证消息有序性的业务场景，Key的选择更为重要，可以通过选择唯一标识的内容来作为Key，比如：用户ID、订单ID。
- 【监控和调整分区策略】：实时监控分区效果（监控Partition的负载和性能），合理进行动态调整（包括分区策略和分区数量），保证系统的高效运行。

- 【实现高性能生产者】：批量发送消息（提高网络和存储效率，减少延迟）和异步发送消息（提高消息的发送性能）



## Offset





# 相关八股 | 机制

## Replica

> 参考文章：[链接](https://www.cnblogs.com/caoweixiong/p/12049462.html)

### 基本概念

==副本的定义==

Kafka中有主题Topic的概念。在Topic下面，有分区Partition的概念，副本Replica就是在分区层次中的概念。

每个分区有多个副本Replica，即有多份数据备份。

---

==副本中的角色==

![image-20250408103753113](./assets/image-20250408103753113.png)

在Kafka中，副本间保持数据同步的方式是【基于领导者（Leader-Based）的副本机制】

- 每个Partition的副本分为2类：领导者副本和追随者副本。每个Partition在创建的时候会选取一个领导者副本，其余副本就是追随者副本；
- Kafka的副本机制比其他分布式系统要更严格一些，追随者副本不对外提供服务（读写请求都不响应，仅领导者副本会提供该Partition的读写请求），仅是作为数据备份，从领导者副本中**异步拉取消息**，并写入到自己的提交日志中，从而完成数据同步。
- 当领导者副本挂掉了，或者说领导者副本所在的 Broker宕机时，Kafka 依托于 ZooKeeper  提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。老 Leader  副本重启回来后，只能作为追随者副本加入到集群中。

---

==【八股】Kafka中的副本不对外提供读、写服务，这样设计的好处？==

方便实现“Read-your-writes”

- 即：当数据写入成功的时候，就能读取到数据；
- 若允许追随者副本提供读服务，因为消息的异步同步需要时间，则会造成延迟，客户端就无法立即看到最新的消息。

方便实现单调读：

- 什么是单调读呢？就是对于一个消费者用户而言，在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在。
- 如果允许追随者副本提供读服务，那么假设当前有 2 个追随者副本 F1 和 F2，它们异步地拉取领导者副本数据。倘若 F1 拉取了 Leader 的最新消息而 F2  还未及时拉取，那么，此时如果有一个消费者先从 F1 读取消息之后又从 F2  拉取消息，它可能会看到这样的现象：第一次消费时看到的最新消息在第二次消费时不见了，这就不是单调读一致性。但是，如果所有的读请求都是由  Leader 来处理，那么 Kafka 就很容易实现单调读一致性。



### AR、OSR、ISR

==概念解释==

AR（Assigned Replicas）：

- 分区中所有的副本；

ISR（In-Sync Replicas）：

- ISR是AR的一个子集，由领导者副本来维护；
- ISR里面包含领导者副本本身和能正常完成数据同步的追随者副本；

OSR（Outof-Sync Replicas）：

- 追随者副本从领导者副本同步数据的时候，存在一定延迟。当延迟超过某个阈值，就会把该追随者副本踢出ISR列表，并加入到OSR列表中；
- 新加入的追随者副本也会先存放在OSR中。

---

==【八股】Kafka判定一个追随者副本是否正常同步领导者副本消息的依据是什么？==

依据是**时间**，不是**数量**。有个阈值参数：`replica.lag.time.max.ms`。

- 当领导者副本消息的写入速度 > 追随者副本的消息同步速度，就会造成数据同步延迟，这个延迟的持续时间如果超过上述阈值后，就会认为数据是不同步的，即将该追随者副本踢出ISR；
- 若被踢出ISR列表的追随者副本，其消息逐渐与领导者副本同步，还会被重新加入ISR列表。

---

==【八股】Kafka中维护ISR列表的地方有哪些？==

Controller维护

- Kafka从集群中选取一个Broker为Controller，负责Partition的管理和副本状态管理；

Leader来维护

- 领导者副本有单独的线程，定期检测ISR中的追随者副本是否脱离ISR。如果发生变化，会将新的ISR消息返回到zookeeper的相关饥饿点中；





### Unclean领导者选举

**情景**

ISR是可以动态调整的，如果ISR列表为空，即领导者副本也挂掉了，该怎么选取新的Leader？

**面临的问题**

ISR列表为空，表明所有追随者副本的消息是落后于领导者副本的。

- 如果从这些追随者副本中选取Leader，就会造成数据丢失，但能保证服务正常提供；
- 如果不从中选取Leader，虽然维护了数据一致性，但是不得不对外停止服务；

**参数设置**

Broker端的参数` unclean.leader.election.enable`

- 开启该参数，表明允许从消息落后的追随者副本中选取Leader；
- 关闭该参数，反之。

建议**不要**开始开启该参数





# 其他

==【八股】Kafka如何实现高吞吐率？==

**顺序读写**

- Kafka的消息是不断追加写到文件中，这个特性可以减少硬盘磁头的寻道时间，充分利用磁盘的顺序读写性能；

**零拷贝**

- 消费者消费消息涉及数据从Broker到Consumer的传递，这个网络传递信息的过程需要数据拷贝；
- 零拷贝可以在数据复制过程中，减少2次上下文切换的开销，提升一倍的性能；

**文件分段**

- Kafka中的Topic分为多个Partition，每个Partition可以分为多个Segment段；
- 每次都是针对一部分数据进行操作，轻便快捷，并且可以增加并行处理能力；

**批量发送**

- Producer -> Broker：Producer可以将消息缓存到本地，等满足要求后，批量发送给Broker；
- Broker -> Consumer：Consumer可以通过Pull模式，批量拉取消息进行消费；

**数据压缩**

- Kafka支持对消息集合进行压缩，Producer负责压缩消息，Consumer负责解压缩，从而减少传输的数据量，减轻网络传输的压力；

- 上述过程虽然增加了CPU的工作，但在面对大数据处理上，瓶颈在网络IO上，所以这点成本开销可以接受；

**其他**

- Kafka不保存消息“是否被消费的状态”，而是通过Offset来确认（Offset之前的是已消费的消息，Offset之后是未消费的消息），并且Offset可以任意移动；
